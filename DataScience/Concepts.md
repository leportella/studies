## Data Analysis Procedures

Data analysis procedures can be dichtomized as either exploratory or confirmatory, based on the availability of appropriate models
for the data source, but a key element in both types of procedures (whether for hypothesis formation or decision making) is the 
grouping, or classification of measurements based on either (i) goodness-of-fit to a postulated model or (ii) natural grouping 
(clustering) revelead through analysis (Jain et. al, 1999).

## Variables

Regardless of what we are trying to measure, the qualities that make a good measure of a scientific concept are high reliability, absece of bias, loew cost, practicality, objectivity, high acceptance and high concept validity. Precision or reliability refers to the reproducibility of repeated measurements, while bias refers to how far the average of many measurements is from the true value. 




## Small Dictionary

**Bias**: refers to the difference between the measure and some "true" value. A difference between and *individual* measurement and the true value is called an error. The bias is the average difference over many measurements.

**Clustering**: is the unsupervised classification of patterns (observations, data items or feature vector) 
into groups (clusters). Intuitively, patterns within a valid cluster are more similar to each other than they are
to a pattern belonging to a different cluster (Jain et. al, 1999).

**Explanatory variables**: include variables purposely manipulated in an experiment and variables that are not purposely manipulated, but are thought to possibly affect the outcome. Complete or partial synonyms include independent variable (IV), covariate, blocking factor and predictor variable.

**Fat-tail**: When a histogram has a lot of values far from the mean relative to a Gaussian distribution. This corresponds to 
positive kurtosis. On a boxplot, many outliers suggests fat tails or possibly data entry errors, while short whiskers suggest 
negative kurtosis, at least if the sample size is large.

**K-mean technique**: The k-means algorithm takes a dataset X of N points as input, together with a parameter K specifying how 
many clusters to create. The output is a set of K cluster centroids and a labeling of X that assigns each of the points in X to a 
unique cluster. All points within a cluster are closer in distance to their centroid than they are to any other centroid.

**Operationalization**: the formal procedure that links scientific concepts to data collection. Operationalization define measures and variables which are quantities of interest or which serve as the practical substitutes for the concepts of interest. For example, if you have a theory about what affects people's anger level, you need to operationalize the concept of anger.

**Outcome variables**: same as dependent variable or DV.

**Statistical models**: are ideal, mathematical representations of observable characteristics. Models are best divided into two
components. The structural componenent (or structural model or signal) specifies the relationship between explanatory variables 
and the mean (or other key feature) of the outcome variables. The "random" or "error" component of the model (or error model or 
noise) characterizes the deviations of the individual observations from the mean. Note that "error" doesn't mean "mistake".




Jain, A.K.; Murty, M.N.; Flynn, P.J.; Data Clustering: A review. ACM Computing Surveys, Vol. 31, No. 3, 1999.
